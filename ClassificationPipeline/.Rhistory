theme(plot.title = element_text(size=plot_title_size, family="Futura",
face="bold.italic", colour = legend_title_color),
plot.subtitle = element_text(margin = margin(5, 0, 0, 10)),
axis.title.x = element_text(face="bold.italic", , family="Geneva",
size = axis_label_size),
axis.title.y = element_text(face="bold.italic", family="Geneva",
size = axis_label_size),
axis.text.x = element_text(face="bold", family="American Typewriter", size = axis_tick_size),
axis.text.y = element_text(face="bold", family="American Typewriter", size = axis_tick_size),
panel.background = element_rect(fill = "white"))
p1
col = 2
palate = c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a')
p1 <- ggplot(data=debrujin_trainDataBacc, aes(x=debrujin_trainDataBacc[, col], y=reorder(Model, -debrujin_trainDataBacc[, col]),
fill = Model)) +
geom_boxplot(show.legend = FALSE, fatten=0.5)
p1 <- p1 + labs(x = x_axis_label, y = y_axis_label,
title = title1, subtitle = "") +
theme(plot.title = element_text(size=plot_title_size, family="Futura",
face="bold.italic", colour = legend_title_color),
plot.subtitle = element_text(margin = margin(5, 0, 0, 10)),
axis.title.x = element_text(face="bold.italic", , family="Geneva",
size = axis_label_size),
axis.title.y = element_text(face="bold.italic", family="Geneva",
size = axis_label_size),
axis.text.x = element_text(face="bold", family="American Typewriter", size = axis_tick_size),
axis.text.y = element_text(face="bold", family="American Typewriter", size = axis_tick_size),
panel.background = element_rect(fill = "white"))
p1
p1 <- p1 + labs(x = x_axis_label, y = y_axis_label,
title = title1, subtitle = "") +
theme(plot.title = element_text(size=plot_title_size, family="Futura",
face="bold.italic", colour = legend_title_color),
plot.subtitle = element_text(margin = margin(5, 0, 0, 10)),
axis.title.x = element_text(face="bold.italic", , family="Geneva",
size = axis_label_size),
axis.title.y = element_text(face="bold.italic", family="Geneva",
size = axis_label_size),
axis.text.x = element_text(face="bold", family="Lucida Grande", size = axis_tick_size),
axis.text.y = element_text(face="bold", family="Lucida Grande", size = axis_tick_size),
panel.background = element_rect(fill = "white"))
p1
trainData1 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/debrujin_runs/train_sw_results.csv",
stringsAsFactors = FALSE, sep=",")
testData1 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/debrujin_runs/test_sw_results.csv",
stringsAsFactors = FALSE, sep=",")
trainData2 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/debrujin_blast/train_db_results.csv",
stringsAsFactors = FALSE, sep=",")
testData2 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/debrujin_blast/test_db_results.csv",
stringsAsFactors = FALSE, sep=",")
trainData3 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/random100_avg/train_random100_results.csv",
stringsAsFactors = FALSE, sep=",")
testData3 <- read.csv2(file = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/random100_avg/test_random100_results.csv",
stringsAsFactors = FALSE, sep=",")
out_dir = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/"
out_file = "TimpBA.png"
source("plotResults.R")
# Set plot label and size parameters
plot_title_size = 14
subplot_title_size = 13
axis_label_size = 12
axis_tick_size = 11
legend_title_color = "Black"
num_top = 10
outFileName = ""
outFilePath = file.path(out_dir, out_file)
select_topN <- function(someData, num_top){
temp = as.vector(unique(someData$Model)[1:num_top])
someData <- someData[someData$Model %in% temp, ]
return(someData)
}
# Process raw data
process_data <- function(rawData, type_data, num_top, miss_records){
rawData$Model <- factor(rawData$Model)
rawData$Baccuracy <- as.numeric(rawData$Baccuracy)
rawData$F1 <- as.numeric(rawData$F1)
DataBacc <- rawData[, c(1, 8)]
DataF1 <- rawData[, c(1, 7)]
DataBacc <- DataBacc[order(DataBacc$Baccuracy, decreasing=TRUE), ]
DataF1 <- DataF1[order(DataF1$F1, decreasing=TRUE), ]
# rawData$Baccuracy <- as.numeric(rawData$Accuracy)
# rawData$F1 <- as.numeric(rawData$F1)
#
# DataBacc <- rawData[, c(1, 2)]
# DataF1 <- rawData[, c(1, 7)]
#
# DataBacc <- DataBacc[order(DataBacc$Accuracy, decreasing=TRUE), ]
# DataF1 <- DataF1[order(DataF1$F1, decreasing=TRUE), ]
if (miss_records == TRUE){
DataBacc <- DataBacc[-which((DataBacc$Model) %in% c("nb", "cforest", "rda", "dwdRadial", "svmRadial", "svmRadialCost")),]
DataF1 <- DataF1[-which((DataF1$Model) %in% c("nb", "cforest", "rda", "dwdRadial", "svmRadial", "svmRadialCost", "bagEarthGCV")),]
}
# Select top models for visualization
if (type_data == "train"){
DataBacc <- select_topN(DataBacc, num_top)
DataF1 <- select_topN(DataF1, num_top)
}
else if (type_data == "test"){
DataBacc <- DataBacc[!duplicated(DataBacc$Model), ]
DataBacc <- DataBacc[1:num_top, ]
DataF1 <- DataF1[!duplicated(DataF1$Model), ]
DataF1 <- DataF1[1:num_top, ]
}
return(list(DataBacc, DataF1))
}
out <- process_data(trainData1, "train", num_top, FALSE)
debrujin_trainDataBacc <- out[[1]]
debrujin_trainDataF1 <- out[[2]]
out <- process_data(testData1, "test", num_top, FALSE)
debrujin_testDataBacc <- out[[1]]
debrujin_testDataF1 <- out[[2]]
# source("plotResults.R")
out <- plot_on_grid(debrujin_trainDataBacc, debrujin_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p1 <- out[[1]]
p2 <- out[[2]]
out <- plot_on_grid(debrujin_trainDataF1, debrujin_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p3 <- out[[1]]
p4 <- out[[2]]
title = paste("(A) Smith Waterman aligned Debruijn motifs", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot1 <- grid.arrange(grid_title, arrangeGrob(p1, p2, ncol=2), heights=c(0.5, 10))
plot2 <- grid.arrange(grid_title, arrangeGrob(p3, p4, ncol=2), heights=c(0.5, 10))
out <- process_data(trainData2, "train", num_top, FALSE)
blast_trainDataBacc <- out[[1]]
blast_trainDataF1 <- out[[2]]
out <- process_data(testData2, "test", num_top, FALSE)
blast_testDataBacc <- out[[1]]
blast_testDataF1 <- out[[2]]
out <- plot_on_grid(blast_trainDataBacc, blast_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p5 <- out[[1]]
p6 <- out[[2]]
out <- plot_on_grid(blast_trainDataF1, blast_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p7 <- out[[1]]
p8 <- out[[2]]
title = paste("(A) BLAST aligned Debruijn motifs", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot3 <- grid.arrange(grid_title, arrangeGrob(p5, p6, ncol=2), heights=c(0.5, 10))
plot4 <- grid.arrange(grid_title, arrangeGrob(p7, p8, ncol=2), heights=c(0.5, 10))
out <- process_data(trainData3, "train", num_top, TRUE)
rand_trainDataBacc <- out[[1]]
rand_trainDataF1 <- out[[2]]
out <- process_data(testData3, "test", num_top, FALSE)
rand_testDataBacc <- out[[1]]
rand_testDataF1 <- out[[2]]
out <- plot_on_grid(rand_trainDataBacc, rand_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p9 <- out[[1]]
p10 <- out[[2]]
out <- plot_on_grid(rand_trainDataF1, rand_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p11 <- out[[1]]
p12 <- out[[2]]
title = paste("(B) Randomly sampled motifs (average of 100 trials)", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot5 <- grid.arrange(grid_title, arrangeGrob(p9, p10, ncol=2), heights=c(0.5, 10))
plot6 <- grid.arrange(grid_title, arrangeGrob(p11, p12, ncol=2), heights=c(0.5, 10))
FinalPlot1 <- grid.arrange(plot1, plot3, plot5, nrow=3)
FinalPlot2 <- grid.arrange(plot2, plot4, plot6, nrow=3)
# Save the plot on disk
ggsave(file.path(outFilePath), FinalPlot1, dpi=650, height=18,
width=14, units="in")
out_file = "TimpF1.png"
outFilePath = file.path(out_dir, out_file)
# Save the plot on disk
ggsave(file.path(outFilePath), FinalPlot2, dpi=650, height=18,
width=14, units="in")
source("plotResults.R")
# Set plot label and size parameters
plot_title_size = 14
subplot_title_size = 13
axis_label_size = 12
axis_tick_size = 11
legend_title_color = "Black"
num_top = 10
outFileName = ""
outFilePath = file.path(out_dir, out_file)
select_topN <- function(someData, num_top){
temp = as.vector(unique(someData$Model)[1:num_top])
someData <- someData[someData$Model %in% temp, ]
return(someData)
}
# Process raw data
process_data <- function(rawData, type_data, num_top, miss_records){
rawData$Model <- factor(rawData$Model)
rawData$Baccuracy <- as.numeric(rawData$Baccuracy)
rawData$F1 <- as.numeric(rawData$F1)
DataBacc <- rawData[, c(1, 8)]
DataF1 <- rawData[, c(1, 7)]
DataBacc <- DataBacc[order(DataBacc$Baccuracy, decreasing=TRUE), ]
DataF1 <- DataF1[order(DataF1$F1, decreasing=TRUE), ]
# rawData$Baccuracy <- as.numeric(rawData$Accuracy)
# rawData$F1 <- as.numeric(rawData$F1)
#
# DataBacc <- rawData[, c(1, 2)]
# DataF1 <- rawData[, c(1, 7)]
#
# DataBacc <- DataBacc[order(DataBacc$Accuracy, decreasing=TRUE), ]
# DataF1 <- DataF1[order(DataF1$F1, decreasing=TRUE), ]
if (miss_records == TRUE){
DataBacc <- DataBacc[-which((DataBacc$Model) %in% c("nb", "cforest", "rda", "dwdRadial", "svmRadial", "svmRadialCost")),]
DataF1 <- DataF1[-which((DataF1$Model) %in% c("nb", "cforest", "rda", "dwdRadial", "svmRadial", "svmRadialCost", "bagEarthGCV")),]
}
# Select top models for visualization
if (type_data == "train"){
DataBacc <- select_topN(DataBacc, num_top)
DataF1 <- select_topN(DataF1, num_top)
}
else if (type_data == "test"){
DataBacc <- DataBacc[!duplicated(DataBacc$Model), ]
DataBacc <- DataBacc[1:num_top, ]
DataF1 <- DataF1[!duplicated(DataF1$Model), ]
DataF1 <- DataF1[1:num_top, ]
}
return(list(DataBacc, DataF1))
}
out <- process_data(trainData1, "train", num_top, FALSE)
debrujin_trainDataBacc <- out[[1]]
debrujin_trainDataF1 <- out[[2]]
out <- process_data(testData1, "test", num_top, FALSE)
debrujin_testDataBacc <- out[[1]]
debrujin_testDataF1 <- out[[2]]
# source("plotResults.R")
out <- plot_on_grid(debrujin_trainDataBacc, debrujin_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p1 <- out[[1]]
p2 <- out[[2]]
out <- plot_on_grid(debrujin_trainDataF1, debrujin_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p3 <- out[[1]]
p4 <- out[[2]]
title = paste("(A) Smith Waterman aligned Debruijn motifs", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot1 <- grid.arrange(grid_title, arrangeGrob(p1, p2, ncol=2), heights=c(0.5, 10))
plot2 <- grid.arrange(grid_title, arrangeGrob(p3, p4, ncol=2), heights=c(0.5, 10))
out <- process_data(trainData2, "train", num_top, FALSE)
blast_trainDataBacc <- out[[1]]
blast_trainDataF1 <- out[[2]]
out <- process_data(testData2, "test", num_top, FALSE)
blast_testDataBacc <- out[[1]]
blast_testDataF1 <- out[[2]]
out <- plot_on_grid(blast_trainDataBacc, blast_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p5 <- out[[1]]
p6 <- out[[2]]
out <- plot_on_grid(blast_trainDataF1, blast_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p7 <- out[[1]]
p8 <- out[[2]]
title = paste("(A) BLAST aligned Debruijn motifs", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot3 <- grid.arrange(grid_title, arrangeGrob(p5, p6, ncol=2), heights=c(0.5, 10))
plot4 <- grid.arrange(grid_title, arrangeGrob(p7, p8, ncol=2), heights=c(0.5, 10))
out <- process_data(trainData3, "train", num_top, TRUE)
rand_trainDataBacc <- out[[1]]
rand_trainDataF1 <- out[[2]]
out <- process_data(testData3, "test", num_top, FALSE)
rand_testDataBacc <- out[[1]]
rand_testDataF1 <- out[[2]]
out <- plot_on_grid(rand_trainDataBacc, rand_testDataBacc, "(A) Balanced accuracy on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) Balanced accuracy on test data",
paste("Balanced accuracy for top", num_top, "models"), "",
"Accuracy", 2, subplot_title_size, axis_label_size, axis_tick_size)
p9 <- out[[1]]
p10 <- out[[2]]
out <- plot_on_grid(rand_trainDataF1, rand_testDataF1, "(A) F1 score on the validation data",
paste("Boxplots for top", num_top, "models"), "(B) F1 score on test data",
paste("F1 values for top", num_top, "models"), "",
"F1 score", 2, subplot_title_size, axis_label_size, axis_tick_size)
p11 <- out[[1]]
p12 <- out[[2]]
title = paste("(B) Randomly sampled motifs (average of 100 trials)", sep="")
grid_title <- textGrob(title, gp = gpar(fontsize = plot_title_size, fontface = 'bold', family="Futura"))
plot5 <- grid.arrange(grid_title, arrangeGrob(p9, p10, ncol=2), heights=c(0.5, 10))
plot6 <- grid.arrange(grid_title, arrangeGrob(p11, p12, ncol=2), heights=c(0.5, 10))
FinalPlot1 <- grid.arrange(plot1, plot3, plot5, nrow=3)
FinalPlot2 <- grid.arrange(plot2, plot4, plot6, nrow=3)
# Save the plot on disk
ggsave(file.path(outFilePath), FinalPlot2, dpi=650, height=18,
width=14, units="in")
out_file = "TimpBA.png"
outFilePath = file.path(out_dir, out_file)
# Save the plot on disk
ggsave(file.path(outFilePath), FinalPlot1, dpi=650, height=18,
width=14, units="in")
setwd("~/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/ClassificationPipeline")
path = getwd()
setwd(file.path(path))
base_path = dirname(path)
if (length(args) < 3){
print("Expects at-least 3 arguments, as follows:")
print("if the program is already running: yes/no")
print("Name of the outut directory: my_out_dir")
print("Name of the input file (in this case, it's fixes): 308_full.csv")
print("Whether upsampling is required: TRUE/FALSE")
print()
print("Here is a sample run (you can copy and paste it in the terminal directly to run the program)")
print("Rscript classificationPipeline.R no test_output 308_full.csv TRUE")
stop(exiting)
}
args = commandArgs(trailingOnly=TRUE)
if (length(args) < 3){
print("Expects at-least 3 arguments, as follows:")
print("if the program is already running: yes/no")
print("Name of the outut directory: my_out_dir")
print("Name of the input file (in this case, it's fixes): 308_full.csv")
print("Whether upsampling is required: TRUE/FALSE")
print()
print("Here is a sample run (you can copy and paste it in the terminal directly to run the program)")
print("Rscript classificationPipeline.R no test_output 308_full.csv TRUE")
stop(exiting)
}
already_running = "no"
result_dir_name = "test_results"
input_file_name = "308_full.csv"
upsample = "FALSE"
out_dir = file.path(base_path, result_dir_name)
if ( (dir.exists(out_dir)) && (already_running == "no") ){
time_stamp = format(Sys.time(), "%m_%d_%H-%m-%S")
new_name = paste(out_dir, "_old_", time_stamp, sep="")
file.rename(out_dir, new_name)
dir.create(out_dir)
} else if ( !(dir.exists(out_dir)) && (already_running == "no") ){
dir.create(out_dir)
}
setwd("~/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification")
out_dir = file.path(base_path, result_dir_name)
if ( (dir.exists(out_dir)) && (already_running == "no") ){
time_stamp = format(Sys.time(), "%m_%d_%H-%m-%S")
new_name = paste(out_dir, "_old_", time_stamp, sep="")
file.rename(out_dir, new_name)
dir.create(out_dir)
} else if ( !(dir.exists(out_dir)) && (already_running == "no") ){
dir.create(out_dir)
}
print(paste("Started execution on:", Sys.time()))
print("###################################")
print("1 Install packages")
print("###################################")
source("InstallMissingPackages.R")
setwd("~/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/ClassificationPipeline")
source("InstallMissingPackages.R")
source("visualizeTopResults.R")
source("visualizeAllResults.R")
source("visualizeTopResults.R")
source("visualizeAllResults.R")
availableModels = install_missing_packages(file.path("classModelList.txt"))
print("###################################")
print("2 READ/COMBINE DATA")
print("###################################")
source("DataIO.R")
out <- load_data(file.path(base_path, "data", input_file_name), upsample)
train_data <- out[[1]]
test_data <- out[[2]]
test_data$target <- as.factor(test_data$target)
source("runModels.R")
time_limit = 1000
number <- 5
repeats <- 1
num_mdls <- 2
show_top <- 10
print("###################################")
print("3 RUN MODELS FOR PREDICTING REAL COMPONENT OF IMPEDANCE")
print("###################################")
train_out_file = "train_results.csv"
test_out_file = "test_results.csv"
stat_file = "Timp_stat.csv"
plot_file = "Timp.png"
trainFilePath = file.path(out_dir, train_out_file)
testFilePath = file.path(out_dir, test_out_file)
head(train_data)
out_dir
train_out = ""
test_out = ""
failCounter = 0;
allresultsDF = data.frame()
output_path = out_dir
output_path = "/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/TIMP_Classification/"
set.seed(100)
control <- trainControl(method = "repeatedcv",
number = number,
repeats = repeats,
savePredictions = "final",
index = createResample(train_data$target, number*repeats),
classProbs = TRUE)
train_out = file.path(output_path, train_out_file)
test_out = file.path(output_path, test_out_file)
res_stats = file.path(output_path, stat_file)
num_mdls
if (num_mdls > 0){
selected_Models = availableModels[(length(availableModels)-num_mdls):length(availableModels)]
} else if (num_mdls == 0){
selected_Models = availableModels
}
selected_Models
for(i in 1:length(selected_Models)){
print(paste("Running", selected_Models[i]))
result <- tryCatch(
{
withTimeout(
{
caret::train(target~., data=train_data, method=selected_Models[i],
trControl = control, preProcess= c("center","scale"), metric="RUC")
}, timeout = time_limit)
},
TimeoutException = function(ex) {
result = "timeout"
print(paste("Timeout for ", selected_Models[i]))
},
error = function(err){
print(err)
result =  "error"
}
)
}
result
selected_Models = c("wsrf")
for(i in 1:length(selected_Models)){
print(paste("Running", selected_Models[i]))
result <- tryCatch(
{
withTimeout(
{
caret::train(target~., data=train_data, method=selected_Models[i],
trControl = control, preProcess= c("center","scale"), metric="RUC")
}, timeout = time_limit)
},
TimeoutException = function(ex) {
result = "timeout"
print(paste("Timeout for ", selected_Models[i]))
},
error = function(err){
print(err)
result =  "error"
}
)
}
result
resultsDF <- as.data.frame(result$resample)
resultsDF <- resultsDF[, 1]
resultsDF
resultsDF = cbind("Model"=rep(selected_Models[i], length(resultsDF)), "Accuracy"=resultsDF)
resultsDF
intermediate_train_stats <- caret::confusionMatrix(result$pred$pred, result$pred$obs, mode="everything")
intermediate_train_stats
library(ROCR)
result
result$pred
library(ROCR)
perf_AUC=performance(result$pred$pred,"auc")
pred=prediction(result$pred$pred, result$pred$obs)
pred=prediction(result$pred, result$pred$obs)
pred=prediction(result$pred$pred, result$pred$obs)
result$pred$pred
pred=prediction(as.vector(result$pred$pred), as.vector(result$pred$obs))
library(pROC)
roc_nb <- roc(result$pred$pred, result$pred$obs)
results
result
result$pred
true_class <- factor(sample(paste0("Class", 1:2),
size = 1000,
prob = c(.2, .8), replace = TRUE))
true_class <- sort(true_class)
class1_probs <- rbeta(sum(true_class == "Class1"), 4, 1)
class2_probs <- rbeta(sum(true_class == "Class2"), 1, 2.5)
test_set <- data.frame(obs = true_class,
Class1 = c(class1_probs, class2_probs))
test_set$Class2 <- 1 - test_set$Class1
test_set$pred <- factor(ifelse(test_set$Class1 >= .5, "Class1", "Class2"))
test_set
head(test_set)
library(MLeval)
install.packages("MLeval")
library(MLeval)
res <- evalm(result)
res$roc
res$proc
res$stdres
res$optres
res$cc
res$roc
res$cc
res$prg
res$probs
res$optres
res$optres["AUC-ROC",]
res$optres$`Group 1`$Score[13]
res$optres$"Group 1"$Score[13]
